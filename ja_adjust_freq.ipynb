{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "06aa4b74-c301-4fa4-b55f-166101af543d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'jp_util.common_path' from 'D:\\\\02.work_project\\\\jp_util\\\\src\\\\jp_util\\\\common_path.py'>"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jp_util.common_path as cp\n",
    "from jp_util.pandas_util import rd_csv_sig, to_csv_sig\n",
    "from jp_util.file_util import get_obj_by_pickle_path, export_to_pickle_path\n",
    "from jp_util.common_util import l, p\n",
    "import jp_util.jap_base_class as jp\n",
    "from importlib import reload\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "reload(cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "51aae446-2e92-43ba-98d5-8f6b38caff2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133637\n"
     ]
    }
   ],
   "source": [
    "# 获取13万的基础词条\n",
    "df_base_word_130000 = jp.JapBaseWordClass.gen_df_base_word()\n",
    "# df_base_word\n",
    "p(len(df_base_word_130000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d7ef70-446a-453e-81cc-6e3323ea7518",
   "metadata": {},
   "source": [
    "## 词频调整处理步骤\n",
    "### 一. 标注出需要删除的词和哪些是高中词汇 \n",
    "1. 整理2400_v3_raw.csv的词汇， 在原有的基础词条中标注，哪些是高中词汇。共有2648个高中词汇df_merge_base_2400_v3.csv\n",
    "2. 删除13万词汇中的(含特殊字符的词汇，数字，字母，特殊字符等) 540个 special_char_in_base_word.csv \n",
    "3. 删除13万词汇中的 中文词汇  2567个  单词发音(纯中文无pron).xlsx\n",
    "4. 删除徐老师标注的 24个  异常词（'为'出现在中文词中)，所以比徐老师的少1个\n",
    "5. 删除徐老师标注的 66个  特殊名词\n",
    "6. 删除徐老师标注的 176个  语法类\n",
    "7. 删除徐老师标注的 34个  感叹词\n",
    "### 二. 从高中2400, 5000篇阅读的词汇，长词汇，小学馆中将标注需要删除的词删除\n",
    "1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "c137278e-5133-4237-bb74-d4ae3e7525ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2682\n",
      "2624\n",
      "----------------------------------------高中词汇标注完毕ok----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 1. 整理2400_v3_raw.csv的词汇， 在原有的基础词条中标注，哪些是高中词汇。\n",
    "df_2400_v3 = rd_csv_sig(cp.r_word_2400_v3_csv)\n",
    "p(len(df_2400_v3))\n",
    "\n",
    "# 把2400_v3去重\n",
    "df_2400_v3_drop_dup = df_2400_v3.drop_duplicates(subset=[\"spell\"], keep=\"first\")\n",
    "p(len(df_2400_v3_drop_dup))\n",
    "\n",
    "df_merge_base_2400_v3 = pd.merge(\n",
    "    df_base_word_130000,\n",
    "    df_2400_v3_drop_dup[[\"spell\"]],\n",
    "    left_on=\"spell\",\n",
    "    right_on=\"spell\",\n",
    "    how=\"left\",\n",
    "    indicator=\"ck_2400_v3\",\n",
    ")\n",
    "# 标注高中高中词汇，用于后续调整词频\n",
    "df_merge_base_2400_v3[\"is_for_student\"] = np.where(\n",
    "    (df_merge_base_2400_v3[\"spell_type\"] == 1)\n",
    "    | (df_merge_base_2400_v3[\"ck_2400_v3\"] == \"both\"),\n",
    "    1,\n",
    "    0,\n",
    ")\n",
    "\n",
    "to_csv_sig(df_merge_base_2400_v3, \"d:/tmp/df_merge_base_2400_v3.csv\")\n",
    "l(\"高中词汇标注完毕ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "255e3e58-48a4-450b-b668-54079c5c4bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------ok----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 包含特殊字符的词(数字，符号，英文)\n",
    "filtered_df_freq = df_base_word_130000[\n",
    "    df_base_word_130000[\"spell\"].str.contains(cp.filter_pattern, na=False)\n",
    "].copy()\n",
    "to_csv_sig(filtered_df_freq, 'd:/tmp/special_char_in_base_word.csv')\n",
    "l(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "c2731ca0-2fa9-4b1f-95db-ff7550a092c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3407\n",
      "2600\n",
      "----------------------------------------高中排查ok----------------------------------------\n",
      "32022\n",
      "29248\n",
      "词频总数：835479\n",
      "----------------------------------------5000阅读排查ok----------------------------------------\n",
      "841911\n",
      "768406\n",
      "768002\n",
      "----------------------------------------长词汇排查ok----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "### 二. 从高中2400, 5000篇阅读的词汇，长词汇，小学馆中将标注需要删除的词删除\n",
    "to_del = rd_csv_sig(\"D:/Dropbox/06.wanjuan/01.设计/99.基础词汇调整/to_del.csv\")\n",
    "p(len(to_del))\n",
    "\n",
    "# 1.从高中2400中删除 需要删除的词\n",
    "df_2400_v3_drop_dup_filtered = df_2400_v3_drop_dup[\n",
    "    ~df_2400_v3_drop_dup[\"spell\"].isin(to_del[\"spell\"])\n",
    "]\n",
    "p(len(df_2400_v3_drop_dup_filtered))\n",
    "to_csv_sig(df_2400_v3_drop_dup_filtered, \"d:/tmp/df_2400_v3_drop_dup_filtered.csv\")\n",
    "l(\"高中排查ok\")\n",
    "\n",
    "# 2.5000篇阅读词汇排查\n",
    "df_5000_word = rd_csv_sig(\"D:/Dropbox/06.wanjuan/99.tmp/tiku_freq_sudachipy_B.csv\")\n",
    "p(len(df_5000_word))\n",
    "df_5000_word = df_5000_word[\n",
    "    ~df_5000_word[\"spell\"].isin(to_del[\"spell\"])\n",
    "].copy()\n",
    "p(len(df_5000_word))\n",
    "df_5000_word.rename(columns={\"spell\": \"5000_spell\", \"count\": \"5000_freq\"}, inplace=True)\n",
    "sum_5000_word = sum(df_5000_word[\"5000_freq\"])\n",
    "print(f'词频总数：{sum_5000_word}')\n",
    "df_5000_word[\"5000_freq_per\"] = round(df_5000_word[\"5000_freq\"] / sum_5000_word, 10)\n",
    "df_5000_word.sort_values([\"5000_freq\"],ascending=False, inplace=True)\n",
    "df_5000_word.reset_index(inplace=True, drop=True)\n",
    "df_5000_word.insert(0, \"5000_word_rank\", range(1, len(df_5000_word) + 1))\n",
    "\n",
    "\n",
    "\n",
    "to_csv_sig(df_5000_word, \"d:/tmp/df_5000_word_filtered.csv\")\n",
    "l(\"5000阅读排查ok\")\n",
    "\n",
    "\n",
    "# 3. 长词汇排查\n",
    "df_long_word_pkl_path = 'd:/95.pickle_files/df_long_word.pkl'\n",
    "\n",
    "if os.path.exists(df_long_word_pkl_path):\n",
    "    df_long_word = get_obj_by_pickle_path(df_long_word_pkl_path)\n",
    "else:\n",
    "    df_long_word = pd.read_csv(\n",
    "        \"d:/03.bigfile/BCCWJ_frequencylist_luw2_ver1_0.tsv\",\n",
    "        encoding=\"utf-8-sig\",\n",
    "        on_bad_lines=\"skip\",\n",
    "        engine=\"python\",\n",
    "        sep=\"\\t\",\n",
    "    )\n",
    "    export_to_pickle_path(df_long_word, df_long_word_pkl_path)\n",
    "p(len(df_long_word))\n",
    "\n",
    "pattern = r\"[˚О○〇◯◎◇✖✕аА▽△▲♪☆★●■☎|。 ̊∙｡･￥\\\"＂〞〝＇＊＃#ⅭK₂ⅡⅢⅣ()\\-－─−←（）〔〕｛｝〒〈〉／;；<=>@＜＞＠、､_【】％+＋！!&＆'%→？…·・“”」～~※℃\\/「｢｣『』{}\\u2460-\\u2473――＝×÷（，＿:：,．\\d\\[\\]\\.\\?\\*a-zA-Z\\uFF21-\\uFF3A\\uFF41-\\uFF5A\\u0391-\\u03A9\\u03B1-\\u03C9]\"\n",
    "#pattern = r\"―\"\n",
    "rec = re.compile(pattern)\n",
    "# df_long_word = df_long_word[~df_long_word[\"lemma\"].str.contains(cp.filter_pattern, na=False)].copy()\n",
    "df_long_word = df_long_word[~df_long_word[\"lemma\"].str.contains(rec, na=False)].copy()\n",
    "p(len(df_long_word))\n",
    "#to_csv_sig(df_long_word,'d:/tmp/df_long_word_tmp.csv')\n",
    "df_long_word = df_long_word[\n",
    "    ~df_long_word[\"lemma\"].isin(to_del[\"spell\"])\n",
    "].copy()\n",
    "p(len(df_long_word))\n",
    "\n",
    "df_long_word.sort_values(\"frequency\", ascending=False, inplace=True)\n",
    "df_long_word=df_long_word.head(30000).copy()\n",
    "df_long_word_summed = df_long_word.groupby(\"lemma\")[\"frequency\"].sum().reset_index()\n",
    "df_long_word_summed.rename(\n",
    "    columns={\"lemma\": \"bccwj_lemma\", \"frequency\": \"bccwj_freq\"}, inplace=True\n",
    ")\n",
    "df_long_word_summed.sort_values(\"bccwj_freq\", ascending=False, inplace=True)\n",
    "bccwj_freq_sum = df_long_word_summed[\"bccwj_freq\"].sum()\n",
    "df_long_word_summed.reset_index(inplace=True, drop=True)\n",
    "df_long_word_summed.insert(0, \"long_word_rank\", range(1, len(df_long_word_summed) + 1))\n",
    "df_long_word_summed[\"bccwj_freq_accu_sum\"] = df_long_word_summed[\"bccwj_freq\"].cumsum()\n",
    "df_long_word_summed[\"bccwj_freq_per\"] = round(\n",
    "    df_long_word_summed[\"bccwj_freq\"] / bccwj_freq_sum, 8\n",
    ")\n",
    "df_long_word_summed[\"bccwj_freq_accu_per\"] = round(\n",
    "    df_long_word_summed[\"bccwj_freq_accu_sum\"] / bccwj_freq_sum, 8\n",
    ")\n",
    "# df_long_word_summed = df_long_word_summed[\n",
    "#     df_long_word_summed[\"bccwj_freq_accu_per\"] <= 0.9\n",
    "# ].copy()\n",
    "\n",
    "to_csv_sig(df_long_word_summed, \"d:/Dropbox/06.wanjuan/99.tmp/df_long_tmp_v2.csv\")\n",
    "\n",
    "l(\"长词汇排查ok\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "644a47bb-e209-424d-8ac7-0dc74916de5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102513\n",
      "101973\n",
      "101827\n",
      "61000\n",
      "----------------------------------------小学馆排查ok----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 4. 小学馆排查\n",
    "df_base_word=rd_csv_sig(cp.w_word_raw_merged_freq_sumed_csv)\n",
    "p(len(df_base_word))\n",
    "pattern = cp.filter_pattern\n",
    "rec = re.compile(pattern)\n",
    "df_base_word = df_base_word[~df_base_word[\"headword\"].str.contains(rec, na=False)].copy()\n",
    "p(len(df_base_word))\n",
    "df_base_word = df_base_word[\n",
    "    ~df_base_word[\"headword\"].isin(to_del[\"spell\"])\n",
    "].copy()\n",
    "p(len(df_base_word))\n",
    "\n",
    "# 取fused_freq>0的\n",
    "df_base_word=df_base_word[df_base_word['fused_freq']>0].copy()\n",
    "df_base_word=df_base_word.head(61000).copy()\n",
    "p(len(df_base_word))\n",
    "cols = [\"word_id\", \"headword\", \"fused_freq\"]\n",
    "df_base_word = df_base_word[cols]\n",
    "sum_base_word = sum(df_base_word[\"fused_freq\"])\n",
    "df_base_word.rename(\n",
    "    columns={\"headword\": \"base_word\", \"fused_freq\": \"base_freq\"}, inplace=True\n",
    ")\n",
    "df_base_word[\"base_freq_per\"] = round(df_base_word[\"base_freq\"] / sum_base_word, 10)\n",
    "\n",
    "df_base_word.sort_values([\"base_freq\"], ascending=False, inplace=True)\n",
    "# df_base_word.reset_index(inplace=True,drop=True)\n",
    "df_base_word.insert(0, \"base_word_rank\", range(1, len(df_base_word) + 1))\n",
    "\n",
    "to_csv_sig(df_base_word,'d:/tmp/df_base_word_tmp.csv')\n",
    "l(\"小学馆排查ok\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "cd1a2b49-97b3-44ef-91ff-f89ed8e5a862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "long word len: 28995\n",
      "base word len: 61000\n",
      "5000 kaokao len: 29248\n",
      "total len: 81642\n",
      "--------------------------------------------------------------------------------\n",
      "long_base_intersection len: 18137\n",
      "long_5000_intersection len: 13534\n",
      "base_5000_intersection len: 16997\n",
      "----------------------------------------ok----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 计算总共需要多少词汇\n",
    "set_long_word = set(df_long_word_summed[\"bccwj_lemma\"])\n",
    "set_base_word = set(df_base_word[\"base_word\"])\n",
    "set_5000_word = set(df_5000_word[\"5000_spell\"])\n",
    "set_all = set_long_word | set_base_word | set_5000_word\n",
    "print(f\"long word len: {len(set_long_word)}\")\n",
    "print(f\"base word len: {len(set_base_word)}\")\n",
    "print(f\"5000 kaokao len: {len(set_5000_word)}\")\n",
    "print(f\"total len: {len(set_all)}\")\n",
    "l()\n",
    "long_base_intersection = set_long_word & set_base_word\n",
    "long_5000_intersection = set_long_word & set_5000_word\n",
    "base_5000_intersection = set_base_word & set_5000_word\n",
    "print(f\"long_base_intersection len: {len(long_base_intersection)}\")\n",
    "print(f\"long_5000_intersection len: {len(long_5000_intersection)}\")\n",
    "print(f\"base_5000_intersection len: {len(base_5000_intersection)}\")\n",
    "\n",
    "l('ok')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "ef06fdc8-fcbc-41ea-bb38-ce484d199940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------ok----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 将4万长词汇， 6万小学馆， 3万的5000篇阅读词汇全汇总\n",
    "df_all = pd.DataFrame(list(set_all), columns=[\"spell_all\"])\n",
    "\n",
    "df_all_m1 = pd.merge(\n",
    "    df_all,\n",
    "    df_long_word_summed[['long_word_rank',\"bccwj_lemma\", \"bccwj_freq_per\"]],\n",
    "    left_on=\"spell_all\",\n",
    "    right_on=\"bccwj_lemma\",\n",
    "    how=\"left\",\n",
    "    indicator=\"ck_long_word\",\n",
    ")\n",
    "\n",
    "df_all_m2 = pd.merge(\n",
    "    df_all_m1,\n",
    "    df_base_word,\n",
    "    left_on=\"spell_all\",\n",
    "    right_on=\"base_word\",\n",
    "    how=\"left\",\n",
    "    indicator=\"ck_base_word\",\n",
    ")\n",
    "\n",
    "df_all_m3 = pd.merge(\n",
    "    df_all_m2,\n",
    "    df_5000_word,\n",
    "    left_on=\"spell_all\",\n",
    "    right_on=\"5000_spell\",\n",
    "    how=\"left\",\n",
    "    indicator=\"ck_5000_word\",\n",
    ")\n",
    "\n",
    "\n",
    "# 筛选出高中词汇 \n",
    "df_2600= df_merge_base_2400_v3[df_merge_base_2400_v3['is_for_student']==1].copy()\n",
    "df_2600 = df_2600[~df_2600[\"spell\"].isin(to_del[\"spell\"])]\n",
    "to_csv_sig(df_2600,\"d:/tmp/df_2600.csv\")\n",
    "\n",
    "df_2600.rename(columns={\"spell\": \"2600_spell\"}, inplace=True)\n",
    "df_all_m4 = pd.merge(\n",
    "    df_all_m3,\n",
    "    df_2600[\"2600_spell\"],\n",
    "    left_on=\"spell_all\",\n",
    "    right_on=\"2600_spell\",\n",
    "    how=\"outer\",\n",
    "    indicator=\"ck_2600_word\",\n",
    ")\n",
    "to_csv_sig(df_all_m4,\"d:/tmp/df_all_m4.csv\")\n",
    "\n",
    "l('ok')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "f3a00516-5163-4e61-8d38-ccbfcec7e496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------ok----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 根据权重计算词频\n",
    "\n",
    "df_all_m4[[\"bccwj_freq_per\", \"base_freq_per\", \"5000_freq_per\"]] = df_all_m4[\n",
    "    [\"bccwj_freq_per\", \"base_freq_per\", \"5000_freq_per\"]\n",
    "].fillna(0)\n",
    "\n",
    "word_5000 = 0.70\n",
    "word_long = 0.20\n",
    "word_base = 0.10\n",
    "\n",
    "df_all_m4[\"final_freq_per\"] = (\n",
    "    df_all_m4[\"5000_freq_per\"]\n",
    "    * np.where(df_all_m4[\"ck_5000_word\"] == \"both\", word_5000, 0)\n",
    "    + df_all_m4[\"bccwj_freq_per\"]\n",
    "    * np.where(df_all_m4[\"ck_long_word\"] == \"both\", word_long, 0)\n",
    "    + df_all_m4[\"base_freq_per\"]\n",
    "    * np.where(df_all_m4[\"ck_base_word\"] == \"both\", word_base, 0)\n",
    ")\n",
    "\n",
    "df_all_m4[\"final_freq_per\"] = np.where(\n",
    "    df_all_m4[\"ck_2600_word\"] != \"left_only\",\n",
    "    df_all_m4[\"final_freq_per\"] + 0.0000492967,\n",
    "    df_all_m4[\"final_freq_per\"],\n",
    ")\n",
    "\n",
    "def cal_freq(freq):\n",
    "    if freq <= 8000:\n",
    "        return freq\n",
    "    elif freq <= 12000:\n",
    "        return round(8000 + (freq - 8000) / 2, 2)\n",
    "    elif freq <= 20000:\n",
    "        return round(10000 + (freq - 12000) / 4, 2)\n",
    "    elif freq <= 30000:\n",
    "        return round(12000 + (freq - 20000) / 8, 2)\n",
    "    elif freq <= 110000:\n",
    "        return round(13250 + (freq - 30000) / 16, 2)\n",
    "    else:\n",
    "        return round(18250 + (freq - 110000) / 100, 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_all_m4_new=df_all_m4.sort_values([\"final_freq_per\"], ascending=False)\n",
    "df_all_m4_new.reset_index(inplace=True, drop=True)\n",
    "df_all_m4_new.insert(0, \"final_freq\", range(1, len(df_all_m4_new) + 1))\n",
    "df_all_m4_new[\"final_freq\"] = df_all_m4_new[\"final_freq\"].apply(cal_freq)\n",
    "\n",
    "to_csv_sig(df_all_m4_new,\"d:/tmp/df_all_m4_new.csv\")\n",
    "l('ok')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "716913bf-132a-4c6d-861c-4d97dc3d32ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------ok----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 和老的词频进行关联， 找到需要删除的word_id， 同时更新词频\n",
    "# 把2600词汇spell填充到df_merged_freq的 spell_all字段里\n",
    "df_all_m4_new[\"spell_all\"] = df_all_m4_new[\"spell_all\"].fillna(\n",
    "    df_all_m4_new[\"2600_spell\"]\n",
    ")\n",
    "df_all_m4_new[\"is_for_student\"] = np.where(\n",
    "    df_all_m4_new[\"ck_2600_word\"].isin([\"both\", \"right_only\"]), 1, 0\n",
    ")\n",
    "\n",
    "to_csv_sig(df_all_m4_new, \"d:/tmp/df_all_m4_new.csv\")\n",
    "\n",
    "\n",
    "df_base_word_130000_to_del = df_base_word_130000[\n",
    "    ~df_base_word_130000[\"spell\"].isin(df_all_m4_new[\"spell_all\"])\n",
    "]\n",
    "df_base_word_remain = df_base_word_130000[\n",
    "    df_base_word_130000[\"spell\"].isin(df_all_m4_new[\"spell_all\"])\n",
    "].copy()\n",
    "\n",
    "freq_mapping = df_all_m4_new.set_index(\"spell_all\")[\"final_freq\"]\n",
    "is_student_mapping = df_all_m4_new.set_index('spell_all')['is_for_student']\n",
    "\n",
    "df_base_word_remain.loc[:, \"frequency\"] = (\n",
    "    df_base_word_remain[\"spell\"]\n",
    "    .map(freq_mapping)\n",
    "    .combine_first(df_base_word_remain[\"frequency\"])\n",
    ")\n",
    "df_base_word_remain.loc[:, \"spell_type\"] = (\n",
    "    df_base_word_remain[\"spell\"]\n",
    "    .map(is_student_mapping)\n",
    "    .combine_first(df_base_word_remain[\"spell_type\"])\n",
    ")\n",
    "df_base_word_remain.sort_values(\"frequency\", ascending=True, inplace=True)\n",
    "\n",
    "to_csv_sig(df_base_word_130000_to_del, \"d:/tmp/df_base_word_130000_to_del.csv\")\n",
    "to_csv_sig(df_base_word_remain, \"d:/tmp/df_base_word_remain.csv\")\n",
    "\n",
    "l(\"ok\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds12_ipy",
   "language": "python",
   "name": "ds12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
